{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e04dd75-fe74-430f-879c-237d731c1a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this section you load the alexnet, the original datas and all the necessery class and functions.\n",
    "#import main_data_aug as main_original "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d5a11b7-fca0-4308-93d9-0d4b8e5ca3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import scipy.io\n",
    "import pandas\n",
    "from scipy.io import loadmat \n",
    "import torch, torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import time \n",
    "import math\n",
    "import random\n",
    "from scipy.fftpack import dct, idct # import for discrete cosine transform\n",
    "from torchsummary import summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96f71ad2-54ca-4b97-93f7-fdc63dd8464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original dataset \n",
    "matPath = \"/Users/diegoperazzolo/Desktop/Documenti_dottorato_padova/DeepLearning_course_nanni/DatasColor_29.mat\"\n",
    "data = scipy.io.loadmat(matPath) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b49ad625-3a18-4e84-9aaa-b986f3b637de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 1 augmented images\n",
    "matPath_m1 = \"/Users/diegoperazzolo/Desktop/Documenti_dottorato_padova/DeepLearning_course_nanni/data_augmented_m1_only_aug.mat\"\n",
    "data_aug_m1 = scipy.io.loadmat(matPath_m1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74d1b159-6d3b-4d99-a596-166ca3a41105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 2 augmented images\n",
    "matPath_m2 = \"/Users/diegoperazzolo/Desktop/Documenti_dottorato_padova/DeepLearning_course_nanni/data_augmented_m2_only_aug.mat\"\n",
    "data_aug_m2 = scipy.io.loadmat(matPath_m2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed54782f-7291-499c-9c06-e85eab99cf1a",
   "metadata": {},
   "source": [
    "## Cration of 2 different datasets (DCT method 1 and DCT method 2) with 100 images synthetic generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4003fa32-ef0c-46bb-8a0f-e7194bf7bccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DATA for method 1 ---\n",
    "\n",
    "#--------------------------------------------------------------------\n",
    "#--- Create the augmented set of images for method 1 ---\n",
    "#--------------------------------------------------------------------\n",
    "list_first_100_m1 = list(data_aug_m1['images'][:100])\n",
    "list_train_original_images = list(data['DATA'][0][0][0][0:299])\n",
    "augmented_m1_dataset_train = list_train_original_images + list_first_100_m1\n",
    "# take the last part of the original dataset and attach it to the the augmented one. \n",
    "original_test_images = list(data['DATA'][0][0][0][299:])\n",
    "final_augmented_m1_dataset_list_images = augmented_m1_dataset_train + original_test_images\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------\n",
    "#--- Create the augmented set of labels for method 1 ---\n",
    "#--------------------------------------------------------------------\n",
    "list_first_100_label_m1 = list(data_aug_m1['labels'][0][:100])\n",
    "list_train_original_label = list(data['DATA'][0][1][0][0:299])\n",
    "augmented_m1_dataset_train_label = list_train_original_label + list_first_100_label_m1\n",
    "# take the last part of the original dataset and attach it to the the augmented one. \n",
    "original_test_label = list(data['DATA'][0][1][0][299:])\n",
    "final_augmented_m1_dataset_list_label = augmented_m1_dataset_train_label + original_test_label\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------\n",
    "#--- Create the augmented set of shuffle for method 1 ---\n",
    "#--------------------------------------------------------------------\n",
    "list_first_100_shuff_m1 = list(data['DATA'][0][2][0][:100])\n",
    "list_train_original_shuff = list(data['DATA'][0][2][0][0:299])\n",
    "augmented_m1_dataset_train_shuff = list_train_original_shuff + list_first_100_shuff_m1\n",
    "# take the last part of the original dataset and attach it to the the augmented one. \n",
    "original_test_shuff = list(data['DATA'][0][2][0][299:])\n",
    "final_augmented_m1_dataset_list_shuff = augmented_m1_dataset_train_shuff + original_test_shuff\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f801c67b-0849-4430-b6b1-3ea53f0b580f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DATA for method 2 ---\n",
    "\n",
    "#--------------------------------------------------------------------\n",
    "#--- Create the augmented set of images for method 1 ---\n",
    "#--------------------------------------------------------------------\n",
    "list_first_100_m2 = list(data_aug_m2['images'][:100])\n",
    "list_train_original_images = list(data['DATA'][0][0][0][0:299])\n",
    "augmented_m2_dataset_train = list_train_original_images + list_first_100_m2\n",
    "# take the last part of the original dataset and attach it to the the augmented one. \n",
    "original_test_images = list(data['DATA'][0][0][0][299:])\n",
    "final_augmented_m2_dataset_list_images = augmented_m2_dataset_train + original_test_images\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------\n",
    "#--- Create the augmented set of labels for method 1 ---\n",
    "#--------------------------------------------------------------------\n",
    "list_first_100_label_m2 = list(data_aug_m2['labels'][0][:100])\n",
    "list_train_original_label = list(data['DATA'][0][1][0][0:299])\n",
    "augmented_m2_dataset_train_label = list_train_original_label + list_first_100_label_m2\n",
    "# take the last part of the original dataset and attach it to the the augmented one. \n",
    "original_test_label = list(data['DATA'][0][1][0][299:])\n",
    "final_augmented_m2_dataset_list_label = augmented_m2_dataset_train_label + original_test_label\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------\n",
    "#--- Create the augmented set of shuffle for method 1 ---\n",
    "#--------------------------------------------------------------------\n",
    "list_first_100_shuff_m2 = list(data['DATA'][0][2][0][:100])\n",
    "list_train_original_shuff = list(data['DATA'][0][2][0][0:299])\n",
    "augmented_m2_dataset_train_shuff = list_train_original_shuff + list_first_100_shuff_m2\n",
    "# take the last part of the original dataset and attach it to the the augmented one. \n",
    "original_test_shuff = list(data['DATA'][0][2][0][299:])\n",
    "final_augmented_m2_dataset_list_shuff = augmented_m1_dataset_train_shuff + original_test_shuff\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec68ecbc-32ab-404c-abd7-cb8a27c6f7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of new file .mat augmented correct: \n",
    "data_dict_m1_aug = {\n",
    "    'images': final_augmented_m1_dataset_list_images,\n",
    "    'labels': final_augmented_m1_dataset_list_label,\n",
    "    'shuffle': final_augmented_m1_dataset_list_shuff \n",
    "}\n",
    "\n",
    "data_dict_m2_aug = {\n",
    "    'images': final_augmented_m2_dataset_list_images, \n",
    "    'labels': final_augmented_m2_dataset_list_label, \n",
    "    'shuffle': final_augmented_m2_dataset_list_shuff\n",
    "}\n",
    "\n",
    "file_path_SD = '/Users/diegoperazzolo/Desktop/Documenti_dottorato_padova/DeepLearning_course_nanni/method_1_data_augmentation_final.mat'\n",
    "scipy.io.savemat(file_path_SD, data_dict_m1_aug)\n",
    "\n",
    "file_path_SD = '/Users/diegoperazzolo/Desktop/Documenti_dottorato_padova/DeepLearning_course_nanni/method_2_data_augmentation_final.mat'\n",
    "scipy.io.savemat(file_path_SD, data_dict_m2_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "860a84bc-a991-4eb3-b928-4b4bf144e137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n",
      "2\n",
      "474\n"
     ]
    }
   ],
   "source": [
    "matPath_m1 = \"/Users/diegoperazzolo/Desktop/Documenti_dottorato_padova/DeepLearning_course_nanni/method_1_data_augmentation_final.mat\"\n",
    "mat_data_m1 = scipy.io.loadmat(matPath_m1)\n",
    "test_m1 = mat_data_m1['images'].astype(np.uint8)\n",
    "print(((test_m1[0].dtype)))\n",
    "print(((mat_data_m1['labels'][0][140])))\n",
    "print((len(mat_data_m1['shuffle'][0])))\n",
    "\n",
    "#check the shape of the images \n",
    "for i in range(len(mat_data_m1['images'])):\n",
    "      if mat_data_m1['images'][i].shape != (312, 417,3) :\n",
    "        print(\"errore nella shape\")\n",
    "        print(i)\n",
    "        print(mat_data_m1['images'][i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec629287-6f3e-4ea1-8d66-bc7c0d7e17d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n",
      "2\n",
      "474\n"
     ]
    }
   ],
   "source": [
    "matPath_m2 = \"/Users/diegoperazzolo/Desktop/Documenti_dottorato_padova/DeepLearning_course_nanni/method_2_data_augmentation_final.mat\"\n",
    "mat_data_m2 = scipy.io.loadmat(matPath_m2)\n",
    "test_m2 = mat_data_m2['images'].astype(np.uint8)\n",
    "print(((test_m2[0].dtype)))\n",
    "print(((mat_data_m2['labels'][0][140])))\n",
    "print((len(mat_data_m2['shuffle'][0])))\n",
    "\n",
    "#check the shape of the images \n",
    "for i in range(len(mat_data_m2['images'])):\n",
    "      if mat_data_m2['images'][i].shape != (312, 417,3) :\n",
    "        print(\"errore nella shape\")\n",
    "        print(i)\n",
    "        print(mat_data_m2['images'][i].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
